{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run.ipynb\n",
    "### This notebook lays out the extended pipeline, including all possibilities of the decision tree, where the run.py path will be extracted from. Preliminaries (Chapter 1) include:\n",
    "1. Loading in the data\n",
    "2. Creating the feature subsets\n",
    "3. Laying out the methods\n",
    "\n",
    "### After this, the pipeline (Chapter 2) can be ran where the different combinations of feature subsets, methods, and hyperparameters will be tested. The results (Chapter 3) of which will be visualized accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inspect\n",
    "\n",
    "from validation import *\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# Paths to train and test folders\n",
    "DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "DATA_TEST_PATH = \"../data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature subsets\n",
    "#### Including:\n",
    "- All the features as is (naive)\n",
    "- Merging highly (t = 0.96) correlated features\n",
    "\n",
    "#### Mixed with:\n",
    "- Categorical feature extraction\n",
    "- Principal Component Analysis features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {}\n",
    "# All the features\n",
    "feature_subsets.update({\"All features\" : [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18, \\\n",
    "                                          19,20,21,22,23,24,25,26,27,28,29]}) \n",
    "# Without highly correlated features\n",
    "feature_subsets.update({\"Without correlated features\" : [0,1,2,3,4,5,7,8,9,10,11,13, \\\n",
    "                                                        14,15,16,17,18,19,20,21,22,23]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {'least_squares' : least_squares, 'least_squares_GD' : least_squares_GD, \\\n",
    "           'least_squares_SGD' : least_squares_SGD, 'ridge_regression' : ridge_regression, \\\n",
    "           'logistic_reg_GD' : logistic_reg_GD, \\\n",
    "           'penalized_logistic_reg_GD' : penalized_logistic_reg_GD #'logistic_reg_newton' : logistic_reg_newton,\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Helper-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Inputs a function and outputs a dictionary with the appropriate param, value pair\n",
    "\"\"\"\n",
    "def get_parameter_values(func, y, tX):\n",
    "    values = {}\n",
    "    mapping = {\n",
    "        'y'         : {'y'         : y},\n",
    "        'tx'        : {'tx'        : tX},\n",
    "        'initial_w' : {'initial_w' : np.zeros(tX.shape[1])},\n",
    "        'max_iters' : {'max_iters' : 100},\n",
    "        'gamma'     : {'gamma'     : True},\n",
    "        'lambda_'   : {'lambda_'   : True}\n",
    "    }\n",
    "    \n",
    "    for param in inspect.signature(func).parameters:\n",
    "        values.update(mapping[param])\n",
    "        \n",
    "    return values\n",
    "\n",
    "\"\"\"\n",
    "    Returns the prediction accuracy using the prototypes and the test set\n",
    "\"\"\"\n",
    "def pred_acc(y, tX, w):\n",
    "    y_pred = np.squeeze(tX @ w)\n",
    "    y_pred[np.where(y_pred <= 0)] = 0\n",
    "    y_pred[np.where(y_pred > 0)] = 1\n",
    "    \n",
    "    return sum(y == y_pred) / len(y)\n",
    "\n",
    "\"\"\"\n",
    "    Performs z-score normalization on the data tX\n",
    "\"\"\"\n",
    "def normalize(tX):\n",
    "    return (tX - np.mean(tX, axis=0)) / np.std(tX, axis=0)\n",
    "\n",
    "\"\"\" \n",
    "    Convert labels from {-1, 1} to {0, 1}. \n",
    "\"\"\"\n",
    "def normalize_labels(y):\n",
    "    return np.round((y + 1) / 2)\n",
    "\n",
    "\"\"\"\n",
    "    Helper function for cross-validation\n",
    "\"\"\"\n",
    "def cross_validation_step(y, tx, indices, k, func, parameters):\n",
    "    # get k'th subgroup in test, others in train\n",
    "    test_indices = indices[k]\n",
    "    train_indices = np.delete(indices, k, axis=0).flat\n",
    "    test_tx, test_y = tx[test_indices], y[test_indices]\n",
    "    train_tx, train_y = tx[train_indices], y[train_indices]\n",
    "    parameters['tx'] = train_tx\n",
    "    parameters['y'] = train_y\n",
    "    # train model on training data\n",
    "    w, _ = func(**parameters)\n",
    "    # calculate the prediction accuracy for test data\n",
    "    return pred_acc(test_y, test_tx, w)\n",
    "\n",
    "\"\"\"\n",
    "    Cross-validation\n",
    "    Returns the mean accuracy of all the folds\n",
    "\"\"\"\n",
    "def cross_validation(y, tx, func, parameters):\n",
    "    indices = build_k_indices(y, 6)\n",
    "    accs = np.array([\n",
    "        cross_validation_step(y, tx, indices, k, func, parameters)\n",
    "        for k in range(len(indices))\n",
    "    ])\n",
    "    return np.mean(accs)\n",
    "\n",
    "\"\"\"\n",
    "    Performs hyperparameter optimization on a function\n",
    "\"\"\"\n",
    "def start(func, parameters):\n",
    "    gammas = lambdas = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    results = []\n",
    "    \n",
    "    if 'gamma' not in parameters and 'lambda_' not in parameters:\n",
    "        w, _ = func(**parameters)\n",
    "        return (w, '-', '-', cross_validation(y, tX, func, parameters))\n",
    "    \n",
    "    if 'gamma' in parameters and 'lambda_' in parameters:\n",
    "        for gamma in gammas:\n",
    "            for lambda_ in lambdas:\n",
    "                parameters['gamma'] = gamma\n",
    "                parameters['lambda_'] = lambda_\n",
    "                w, _ = func(**parameters)\n",
    "                results.append((w, gamma, lambda_, cross_validation(y, tX, func, parameters)))\n",
    "        return results\n",
    "    \n",
    "    if 'gamma' in parameters: \n",
    "        for gamma in gammas:\n",
    "            parameters['gamma'] = gamma\n",
    "            w, _ = func(**parameters)\n",
    "            results.append((w, gamma, '-', cross_validation(y, tX, func, parameters)))\n",
    "        \n",
    "    if 'lambda_' in parameters: \n",
    "        for lambda_ in lambdas:\n",
    "            parameters['lambda_'] = lambda_\n",
    "            w, _ = func(**parameters)\n",
    "            results.append((w, '-', lambda_, cross_validation(y, tX, func, parameters)))\n",
    "        \n",
    "    return max(results, key=lambda x:x[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features with least_squares and gamma:-, lambda:- - accuracy: 0.7184034944559113\n",
      "All features with least_squares_GD and gamma:0.1, lambda:- - accuracy: 0.7141354261668186\n",
      "All features with least_squares_SGD and gamma:1e-05, lambda:- - accuracy: 0.6399302388838222\n",
      "All features with ridge_regression and gamma:-, lambda:0.0001 - accuracy: 0.7178234851757628\n",
      "All features with logistic_reg_GD and gamma:1e-05, lambda:- - accuracy: 0.5810532968527496\n",
      "All features with penalized_logistic_reg_GD and gamma:-, lambda:0.001 - accuracy: 0.5809732955727291\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "y = normalize_labels(y)\n",
    "tX = normalize(tX)\n",
    "\n",
    "for name, features in feature_subsets.items():\n",
    "    for method, func in methods.items():\n",
    "        parameters = get_parameter_values(func, y, tX[:,features])\n",
    "            \n",
    "        w, gamma, lambda_, acc = start(func, parameters)\n",
    "        \n",
    "        print(f\"{name} with {method} and gamma:{gamma}, lambda:{lambda_} = accuracy: {acc}\")\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
