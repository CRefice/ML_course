{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run.ipynb\n",
    "### This notebook lays out the extended pipeline, including all possibilities of the decision tree, where the run.py path will be extracted from. Preliminaries (Chapter 1) include:\n",
    "1. Loading in the data\n",
    "2. Creating the feature subsets\n",
    "3. Laying out the methods\n",
    "\n",
    "### After this, the pipeline (Chapter 2) can be ran where the different combinations of feature subsets, methods, and hyperparameters will be tested. The results (Chapter 3) of which will be visualized accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inspect\n",
    "\n",
    "from validation import *\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# Paths to train and test folders\n",
    "DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "DATA_TEST_PATH = \"../data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, data, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature subsets\n",
    "#### Including:\n",
    "- All the features as is (naive)\n",
    "- Merging highly (t = 0.96) correlated features\n",
    "\n",
    "#### Mixed with:\n",
    "- Categorical feature extraction\n",
    "- Principal Component Analysis features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {\n",
    "    \"All features\" : list(range(data.shape[1])),\n",
    "    \"Without correlated features\" : [0,1,2,3,4,5,7,8,9,10,11,13,\n",
    "                                     14,15,16,17,18,19,20,21,22,23],\n",
    "    \"Without calculated features\" : [0,1,2,3,4,5,7,8,9,10,11,13],\n",
    "    \"Without corr >.8\" : [0,1,2,3,7,8,10,11,13,14,15,16,17,18,19,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    'least_squares' : least_squares, 'least_squares_GD' : least_squares_GD,\n",
    "    'least_squares_SGD' : least_squares_SGD, 'ridge_regression' : ridge_regression,\n",
    "    'logistic_reg_GD' : logistic_reg_GD,\n",
    "    'penalized_logistic_reg_GD' : penalized_logistic_reg_GD\n",
    "    #, 'logistic_reg_newton' : logistic_reg_newton,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Helper-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Inputs a function and outputs a dictionary with the appropriate param, value pair\n",
    "\"\"\"\n",
    "def get_parameter_values(func, y, tX):\n",
    "    values = {}\n",
    "    mapping = {\n",
    "        'y'         : {'y'         : y},\n",
    "        'tx'        : {'tx'        : tX},\n",
    "        'initial_w' : {'initial_w' : np.zeros(tX.shape[1])},\n",
    "        'max_iters' : {'max_iters' : 100},\n",
    "        'gamma'     : {'gamma'     : True},\n",
    "        'lambda_'   : {'lambda_'   : True}\n",
    "    }\n",
    "    \n",
    "    for param in inspect.signature(func).parameters:\n",
    "        values.update(mapping[param])\n",
    "        \n",
    "    return values\n",
    "\n",
    "\"\"\"\n",
    "    Returns the prediction accuracy using the prototypes and the test set\n",
    "\"\"\"\n",
    "def pred_acc(y, tX, w):\n",
    "    y_pred = np.squeeze(tX @ w)\n",
    "    y_pred[np.where(y_pred <= 0)] = 0\n",
    "    y_pred[np.where(y_pred > 0)] = 1\n",
    "    \n",
    "    return sum(y == y_pred) / len(y)\n",
    "\n",
    "\"\"\"\n",
    "    Performs z-score normalization on the data tX\n",
    "\"\"\"\n",
    "def normalize(tX):\n",
    "    return (tX - np.mean(tX, axis=0)) / np.std(tX, axis=0)\n",
    "\n",
    "\"\"\" \n",
    "    Convert labels from {-1, 1} to {0, 1}. \n",
    "\"\"\"\n",
    "def normalize_labels(y):\n",
    "    return np.round((y + 1) / 2)\n",
    "\n",
    "\"\"\"\n",
    "    Helper function for cross-validation\n",
    "\"\"\"\n",
    "def cross_validation_step(y, tx, indices, k, func, parameters):\n",
    "    # get k'th subgroup in test, others in train\n",
    "    test_indices = indices[k]\n",
    "    train_indices = np.delete(indices, k, axis=0).flat\n",
    "    test_tx, test_y = tx[test_indices], y[test_indices]\n",
    "    train_tx, train_y = tx[train_indices], y[train_indices]\n",
    "    parameters['tx'] = train_tx\n",
    "    parameters['y'] = train_y\n",
    "    # train model on training data\n",
    "    w, _ = func(**parameters)\n",
    "    # calculate the prediction accuracy for test data\n",
    "    return pred_acc(test_y, test_tx, w)\n",
    "\n",
    "\"\"\"\n",
    "    Cross-validation\n",
    "    Returns the mean accuracy of all the folds\n",
    "\"\"\"\n",
    "def cross_validation(y, tx, func, parameters):\n",
    "    indices = build_k_indices(y, 10)\n",
    "    accs = np.array([\n",
    "        cross_validation_step(y, tx, indices, k, func, parameters)\n",
    "        for k in range(len(indices))\n",
    "    ])\n",
    "    return np.mean(accs)\n",
    "\n",
    "\"\"\"\n",
    "    Performs hyperparameter optimization on a function\n",
    "\"\"\"\n",
    "def start(func, parameters):\n",
    "    gammas = lambdas = [0.1, 0.05, 0.01]\n",
    "    results = []\n",
    "    \n",
    "    tX = parameters['tx']\n",
    "    y = parameters['y']\n",
    "    \n",
    "    if 'gamma' not in parameters and 'lambda_' not in parameters:\n",
    "        w, _ = func(**parameters)\n",
    "        return (w, '-', '-', cross_validation(y, tX, func, parameters))\n",
    "    \n",
    "    if 'gamma' in parameters and 'lambda_' in parameters:\n",
    "        for gamma in gammas:\n",
    "            for lambda_ in lambdas:\n",
    "                parameters['gamma'] = gamma\n",
    "                parameters['lambda_'] = lambda_\n",
    "                w, _ = func(**parameters)\n",
    "                results.append((w, gamma, lambda_, cross_validation(y, tX, func, parameters)))\n",
    "        return results\n",
    "    \n",
    "    if 'gamma' in parameters: \n",
    "        for gamma in gammas:\n",
    "            parameters['gamma'] = gamma\n",
    "            w, _ = func(**parameters)\n",
    "            results.append((w, gamma, '-', cross_validation(y, tX, func, parameters)))\n",
    "        \n",
    "    if 'lambda_' in parameters: \n",
    "        for lambda_ in lambdas:\n",
    "            parameters['lambda_'] = lambda_\n",
    "            w, _ = func(**parameters)\n",
    "            results.append((w, '-', lambda_, cross_validation(y, tX, func, parameters)))\n",
    "        \n",
    "    return max(results, key=lambda x:x[3])\n",
    "\n",
    "def feature_expansion(tX, degree):\n",
    "    powers = [np.power(tX, deg) for deg in range(1, degree)]\n",
    "    return np.concatenate(powers, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = normalize_labels(labels)\n",
    "tX = normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features with least_squares and gamma:-, lambda:- = accuracy: 0.7183999999999998\n",
      "All features with least_squares_GD and gamma:0.1, lambda:- = accuracy: 0.7144039999999999\n",
      "All features with least_squares_SGD and gamma:0.01, lambda:- = accuracy: 0.6096520000000001\n",
      "All features with ridge_regression and gamma:-, lambda:0.01 = accuracy: 0.71634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/uni/ml/projects/project1/scripts/implementations.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  exp = np.exp(t)\n",
      "/home/carlo/uni/ml/projects/project1/scripts/implementations.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return exp / (1 + exp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features with logistic_reg_GD and gamma:0.1, lambda:- = accuracy: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-932b88b3986d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_parameter_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name} with {method} and gamma:{gamma}, lambda:{lambda_} = accuracy: {acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for name, features in feature_subsets.items():\n",
    "    for method, func in methods.items():\n",
    "        subset = tX[:, features]\n",
    "        parameters = get_parameter_values(func, y, subset)\n",
    "            \n",
    "        w, gamma, lambda_, acc = start(func, parameters)\n",
    "        \n",
    "        print(f\"{name} with {method} and gamma:{gamma}, lambda:{lambda_} = accuracy: {acc}\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2, acc = 0.7313, 0.7310, 0.7312, 0.7315\n",
    "# 3, acc = 0.7199, 0.7268, 0.7271, 0.7300\n",
    "# 4, acc = 0.6921"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
