{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run.ipynb\n",
    "### This notebook lays out the extended pipeline, including all possibilities of the decision tree, where the run.py path will be extracted from. Preliminaries (Chapter 1) include:\n",
    "1. Loading in the data\n",
    "2. Creating the feature subsets\n",
    "3. Laying out the methods\n",
    "\n",
    "### After this, the pipeline (Chapter 2) can be ran where the different combinations of feature subsets, methods, and hyperparameters will be tested. The results (Chapter 3) of which will be visualized accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inspect\n",
    "\n",
    "from validation import *\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# Paths to train and test folders\n",
    "DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "DATA_TEST_PATH = \"../data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature subsets\n",
    "#### Including:\n",
    "- All the features as is (naive)\n",
    "- Merging highly (t = 0.96) correlated features\n",
    "\n",
    "#### Mixed with:\n",
    "- Categorical feature extraction\n",
    "- Principal Component Analysis features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {}\n",
    "# All the features\n",
    "feature_subsets.update({\"All features\" : [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18, \\\n",
    "                                          19,20,21,22,23,24,25,26,27,28,29]}) \n",
    "# Without highly correlated features\n",
    "feature_subsets.update({\"Without correlated features\" : [0,1,2,3,4,5,7,8,9,10,11,13, \\\n",
    "                                                        14,15,16,17,18,19,20,21,22,23]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {'least_squares' : least_squares, 'least_squares_GD' : least_squares_GD, \\\n",
    "           'least_squares_SGD' : least_squares_SGD, 'ridge_regression' : ridge_regression, \\\n",
    "           'logistic_reg_GD' : logistic_reg_GD, 'logistic_reg_newton' : logistic_reg_newton, \\\n",
    "           'penalized_logistic_reg_GD' : penalized_logistic_reg_GD\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Helper-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Inputs a function and outputs a dictionary with the appropriate param, value pair\n",
    "\"\"\"\n",
    "def get_parameter_values(func, y, tX):\n",
    "    values = {}\n",
    "    mapping = {\n",
    "        'y'         : {'y'         : y},\n",
    "        'tx'        : {'tx'        : tX},\n",
    "        'initial_w' : {'initial_w' : np.zeros(tX.shape[1])},\n",
    "        'max_iters' : {'max_iters' : 500},\n",
    "        'gamma'     : {'gamma'     : 10 ** -4},\n",
    "        'lambda_'   : {'lambda_'   : 0.0001}\n",
    "        'gamma'     : {'gamma'     : [0.1,0.01,0.001,0.0001,0.00001]},\n",
    "        'lambda_'   : {'lambda_'   : }\n",
    "    }\n",
    "    \n",
    "    for param in inspect.signature(func).parameters:\n",
    "        values.update(mapping[param])\n",
    "        \n",
    "    return values\n",
    "\n",
    "\"\"\"\n",
    "    Returns the prediction accuracy using the prototypes and the test set\n",
    "\"\"\"\n",
    "def pred_acc(y, tX, w):\n",
    "    y_pred = np.squeeze(tX @ w)\n",
    "    y_pred[np.where(y_pred <= 0)] = 0\n",
    "    y_pred[np.where(y_pred > 0)] = 1\n",
    "    \n",
    "    return sum(y == y_pred) / len(y)\n",
    "\n",
    "\"\"\"\n",
    "    Performs z-score normalization on the data tX\n",
    "\"\"\"\n",
    "def normalize(tX):\n",
    "    return (tX - np.mean(tX, axis=0)) / np.std(tX, axis=0)\n",
    "\n",
    "\"\"\" \n",
    "    Convert labels from {-1, 1} to {0, 1}. \n",
    "\"\"\"\n",
    "def normalize_labels(y):\n",
    "    return np.round((y + 1) / 2)\n",
    "\n",
    "\"\"\"\n",
    "    Performs hyperparameter optimization on a function\n",
    "\"\"\"\n",
    "def start(func, parameters):\n",
    "    indices = build_k_indices(y, 6)\n",
    "    gammas = lambdas = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    results = []\n",
    "    \n",
    "    if 'gamma' not in parameters: \n",
    "        gammas = []\n",
    "    if 'lambda_' not in parameters: \n",
    "        lambdas = []\n",
    "        \n",
    "    # Gridsearch\n",
    "    for gamma in gammas:\n",
    "        for lambda_ in lambdas:\n",
    "            parameters['gamma'] = gamma\n",
    "            parameters['lambda_'] = lambda_\n",
    "            \n",
    "            w, _ = func(**parameters)\n",
    "            \n",
    "            results.append((w, pred_acc(y, tX, w, indices))) # k-fold\n",
    "    \n",
    "    return max(results, key=lambda x:x[1])\n",
    "    # TODO: hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features with least_squares - \n"
     ]
    }
   ],
   "source": [
    "# The result: a list of tuples, [(features, method, acc, w), ...]\n",
    "result = []\n",
    "y = normalize_labels(y)\n",
    "tX = normalize(tX)\n",
    "\n",
    "for name, features in feature_subsets.items():\n",
    "    for method, func in methods.items():\n",
    "        parameters = get_parameter_values(func, y, tX[:,features])\n",
    "            \n",
    "        w, acc = start(func, parameters)\n",
    "        \n",
    "        print(f\"{name} with {method} - accuracy: {acc}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
